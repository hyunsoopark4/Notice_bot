# notice_bot.py  â€• í•™ì‚¬ê³µì§€ + GPT 3ì¤„ ìš”ì•½ (í…Œì´ë¸” íŒŒì‹± í™•ì •íŒ)
import os, re, sys, requests, hashlib, textwrap, traceback
from bs4 import BeautifulSoup
from urllib.parse import urljoin
import openai

# â”€â”€ í™˜ê²½ ë³€ìˆ˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
WEBHOOK    = os.getenv("DISCORD_WEBHOOK_URL")      # í•™ì‚¬ ë””ìŠ¤ì½”ë“œ ì›¹í›…
OPENAI_KEY = os.getenv("OPENAI_API_KEY")           # (ì—†ì–´ë„ ë™ì‘)
openai.api_key = OPENAI_KEY

BASE       = "https://scatch.ssu.ac.kr"
LIST_URL   = f"{BASE}/ê³µì§€ì‚¬í•­"
ID_FILE    = "last_notice_id.txt"
HEADERS    = {"User-Agent": "Mozilla/5.0"}
TIMEOUT    = 15
md5        = lambda s: hashlib.md5(s.encode()).hexdigest()

# â”€â”€ ìµœì‹  ê¸€ ë§í¬ & ID â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def get_latest():
    html = requests.get(LIST_URL, headers=HEADERS, timeout=TIMEOUT).text
    soup = BeautifulSoup(html, "html.parser")

    for tr in soup.select("table.board_list tbody tr"):
        a = tr.find("a", href=True)
        if not a:
            continue
        href = urljoin(BASE, a["href"])
        # ID ì¶”ì¶œ ìš°ì„ ìˆœìœ„: articleId= | ìˆ«ì ë | md5
        m = re.search(r"articleId=(\d+)", href) or re.search(r"/(\d+)$", href)
        aid = m.group(1) if m else md5(href)
        return aid, href
    return None, None

# â”€â”€ ë³¸ë¬¸ ìŠ¤í¬ë˜í•‘ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def fetch_content(link):
    html = requests.get(link, headers=HEADERS, timeout=TIMEOUT).text
    soup = BeautifulSoup(html, "html.parser")
    title = soup.select_one("h4.tit").get_text(" ", strip=True)
    body  = soup.select_one("div.board_view").get_text(" ", strip=True)
    return title, textwrap.shorten(body, 4000)

# â”€â”€ ìš”ì•½ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def gpt_summary(txt):
    prompt = ("ë‹¤ìŒ í•™ì‚¬ ê³µì§€ë¥¼ í•œêµ­ì–´ë¡œ 3ì¤„ ì´í•˜ í•µì‹¬ ìš”ì•½:\n" + txt)
    r = openai.ChatCompletion.create(
        model="gpt-3.5-turbo",
        messages=[{"role": "user", "content": prompt}],
        max_tokens=120, temperature=0.3,
    )
    return r.choices[0].message.content.strip()

def fallback(txt):
    return textwrap.shorten(txt, 200) + "\n(ìš”ì•½ëª¨ë“œ OFF)"

# â”€â”€ ìƒíƒœ íŒŒì¼ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
read_last = lambda: open(ID_FILE).read().strip() if os.path.exists(ID_FILE) else None
write_last = lambda x: open(ID_FILE, "w").write(x)

# â”€â”€ ë””ìŠ¤ì½”ë“œ ì „ì†¡ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def send(msg):
    requests.post(WEBHOOK, json={"content": msg}, timeout=10)

# â”€â”€ ë©”ì¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def main():
    if not WEBHOOK:
        sys.exit("âŒ DISCORD_WEBHOOK_URL ì‹œí¬ë¦¿ì´ ì—†ìŠµë‹ˆë‹¤")

    aid, link = get_latest()
    if not aid:
        print("ğŸš« ëª©ë¡ íŒŒì‹± ì‹¤íŒ¨"); return
    if aid == read_last():
        print("â¸ ìƒˆ ê¸€ ì—†ìŒ"); return

    title, body = fetch_content(link)
    try:
        summary = gpt_summary(body) if OPENAI_KEY else fallback(body)
    except Exception as e:
        print("âš ï¸ GPT ìš”ì•½ ì‹¤íŒ¨:", e)
        summary = fallback(body)

    send(f"ğŸ“š **{title}**\n{summary}\n{link}")
    write_last(aid)
    print("âœ… ê³µì§€ + ìš”ì•½ ì „ì†¡ ì™„ë£Œ")

if __name__ == "__main__":
    main()
