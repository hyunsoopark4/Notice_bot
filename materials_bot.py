# materials_bot.py
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ì‹ ì†Œì¬ê³µí•™ê³¼ ê³µì§€(https://materials.ssu.ac.kr/bbs/board.php?tbl=bbs51)
# ê°€ì¥ ìµœì‹  ê¸€ 1ê±´ì„ ì½ì–´, ìƒˆ ê¸€ì´ë©´ ë””ìŠ¤ì½”ë“œ ì›¹í›…ìœ¼ë¡œ ì•Œë¦¼.

import os, re, sys, requests, hashlib
from datetime import datetime
from bs4 import BeautifulSoup
from urllib.parse import urljoin

WEBHOOK = os.getenv("DISCORD_WEBHOOK_MSE")      # â† ë ˆí¬ Secretsì— ì¶”ê°€
LIST_URL = "https://materials.ssu.ac.kr/bbs/board.php?tbl=bbs51"
ID_FILE  = "last_mse_id.txt"

HEADERS = {"User-Agent": "Mozilla/5.0"}
DATE_RE = re.compile(r"\d{4}[.\-]\d{2}[.\-]\d{2}")

def md5(text: str) -> str:
    return hashlib.md5(text.encode()).hexdigest()

def parse_date(t: str) -> datetime:
    return datetime.strptime(t.strip().replace(".", "-"), "%Y-%m-%d")

def get_latest():
    html = requests.get(LIST_URL, headers=HEADERS, timeout=15).text
    soup = BeautifulSoup(html, "html.parser")

    latest_a, latest_dt = None, datetime.min

    # í‘œ êµ¬ì¡°: <tbody><tr>â€¦</tr></tbody>
    for tr in soup.select("tbody tr"):
        # â‘  ê³ ì • ê³µì§€(ì•„ì´ì½˜/ê¸€ì”¨ 'ê³µì§€')ëŠ” íŒ¨ìŠ¤
        if tr.find("td", string=re.compile("ê³µì§€|Notice", re.I)):
            continue

        # â‘¡ ê¸€ ë§í¬ & ë‚ ì§œ ì°¾ê¸°
        a = tr.find("a", href=True)
        d = tr.find("td", string=DATE_RE)
        if not a:
            continue

        # ë‚ ì§œ ì…€ì´ ì—†ìœ¼ë©´ dtë¥¼ ìµœì†Œê°’ìœ¼ë¡œ ìœ ì§€ â†’ ê²°êµ­ ë§í¬ ì²« ì¤„ ì„ íƒ
        cur_dt = latest_dt
        if d:
            try:
                cur_dt = parse_date(d.text)
            except ValueError:
                pass

        if cur_dt >= latest_dt:
            latest_a, latest_dt = a, cur_dt

    if not latest_a:
        return None, None, None

    link = urljoin("https://materials.ssu.ac.kr", latest_a["href"])
    title = latest_a.get_text(strip=True)

    # wr_id Â· idx ë“±ì´ ì—†ìœ¼ë©´ ë§í¬ ì „ì²´ md5 ë¡œ ì¤‘ë³µíŒë‹¨
    m = re.search(r"(wr_id|idx)=(\d+)", link)
    nid = m.group(2) if m else md5(link)

    return nid, title, link

def read_last():
    try: return open(ID_FILE).read().strip()
    except FileNotFoundError: return None

def write_last(nid): open(ID_FILE, "w").write(nid)

def send(msg):
    requests.post(WEBHOOK, json={"content": msg}, timeout=10)

def main():
    if not WEBHOOK:
        sys.exit("âŒ DISCORD_WEBHOOK_MSE ì‹œí¬ë¦¿ì´ ì—†ìŠµë‹ˆë‹¤")

    nid, title, link = get_latest()
    if not nid:
        print("ğŸš« ê³µì§€ íŒŒì‹± ì‹¤íŒ¨ â€“ ì´ë²ˆ ì£¼ê¸° ìŠ¤í‚µ"); return
    if nid == read_last():
        print("â¸ ìƒˆ ê¸€ ì—†ìŒ"); return

    send(f"ğŸ”¬ **ì‹ ì†Œì¬ê³µí•™ê³¼ ìƒˆ ê³µì§€**\n{title}\n{link}")
    write_last(nid); print("âœ… ìƒˆ ê³µì§€ ì „ì†¡ ì™„ë£Œ")

if __name__ == "__main__":
    main()
